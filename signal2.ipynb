{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39af120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from obspy import read\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import signal\n",
    "from matplotlib import cm\n",
    "import random\n",
    "from obspy.signal.invsim import cosine_taper\n",
    "from obspy.signal.filter import highpass\n",
    "from obspy.signal.trigger import classic_sta_lta, plot_trigger, trigger_onset\n",
    "import librosa\n",
    "import librosa.display\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import itertools\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9248ba8",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b144b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(data, min_freq, max_freq):\n",
    "    data.filter('lowpass',freq=max_freq)\n",
    "    data.filter('highpass',freq=min_freq)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1864cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_mseed(training_path, csv_file, min_freq, max_freq):\n",
    "    mseed_files = glob.glob(os.path.join(training_path, \"*.mseed\"))\n",
    "    data_list = []\n",
    "    target_df = pd.read_csv(csv_file)\n",
    "\n",
    "    for mseed_file in mseed_files:\n",
    "        stream = read(mseed_file)\n",
    "        stream = filter_data(stream, min_freq, max_freq)\n",
    "        filename = os.path.basename(mseed_file).rstrip(\".mseed\")\n",
    "        # print(f\"Processing: {filename}\")\n",
    "        \n",
    "        if 'filename' not in target_df.columns or 'time_rel(sec)' not in target_df.columns:\n",
    "            # print(f\"Error: Columns 'filename' or 'time_rel(sec)' not found in target DataFrame.\")\n",
    "            continue\n",
    "        \n",
    "        target_df['filename'] = target_df['filename'].str.replace('.csv', '', regex=False)\n",
    "        matching_rows = target_df[target_df['filename'] == filename]\n",
    "        if matching_rows.empty:\n",
    "            # print(f\"Warning: No matching filename found in the target DataFrame for {filename}. Skipping this file.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            target = matching_rows['time_rel(sec)'].iloc[0]\n",
    "        except IndexError:\n",
    "            # print(f\"Error: No 'time_rel(sec)' value found for filename {filename}. Skipping this file.\")\n",
    "            continue\n",
    "\n",
    "        for trace in stream:\n",
    "            row = {\n",
    "                \"file_name\": filename,  # File name without path\n",
    "                \"rel_times\": trace.times(),\n",
    "                \"data\": trace.data,\n",
    "                \"start_time\": trace.stats.starttime,  # Absolute start time\n",
    "                \"end_time\": trace.stats.endtime,      # Absolute end time\n",
    "                \"target\": target,                     # Target value for the filename\n",
    "                \"sampling_rate\": trace.stats.sampling_rate,\n",
    "            }\n",
    "            data_list.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    # print(\"Final DataFrame:\\n\", df)\n",
    "    return df\n",
    "\n",
    "def get_data(training_folders, catalog_folders, min_freq=0.5, max_freq=1):\n",
    "    df = pd.DataFrame()\n",
    "    for training_folder, catalog_folder in zip(training_folders, catalog_folders):\n",
    "        new_df = get_data_from_mseed(training_folder, catalog_folder, min_freq, max_freq)\n",
    "        df = pd.concat([df, new_df], axis=0, ignore_index=True)\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d9f280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_mseed_test(test_path, min_freq, max_freq):\n",
    "    mseed_files = glob.glob(os.path.join(test_path, \"*.mseed\"))\n",
    "    data_list = []\n",
    "\n",
    "    for mseed_file in mseed_files:\n",
    "        stream = read(mseed_file)\n",
    "        stream = filter_data(stream, min_freq, max_freq)\n",
    "        filename = os.path.basename(mseed_file).rstrip(\".mseed\")\n",
    "        # print(f\"Processing: {filename}\")\n",
    "\n",
    "        for trace in stream:\n",
    "            row = {\n",
    "                \"file_name\": filename,  # File name without path\n",
    "                \"rel_times\": trace.times(),\n",
    "                \"data\": trace.data,\n",
    "                \"start_time\": trace.stats.starttime,  # Absolute start time\n",
    "                \"end_time\": trace.stats.endtime,      # Absolute end time\n",
    "                \"sampling_rate\": trace.stats.sampling_rate,\n",
    "            }\n",
    "            data_list.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    # print(\"Final DataFrame:\\n\", df)\n",
    "    return df\n",
    "\n",
    "def get_test_data(test_folders, min_freq=0.5, max_freq=1):\n",
    "    df = pd.DataFrame()\n",
    "    for test_folder in test_folders:\n",
    "        new_df = get_data_from_mseed_test(test_folder, min_freq, max_freq)\n",
    "        df = pd.concat([df, new_df], axis=0, ignore_index=True)\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e999c8",
   "metadata": {},
   "source": [
    "### Algorithm Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfed57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(hf_points, _min_dist = 2000):\n",
    "\n",
    "    X = np.array(hf_points).reshape(-1, 1)  \n",
    "\n",
    "    initial_n_clusters = 5 \n",
    "    kmeans = KMeans(n_clusters=initial_n_clusters)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    def filter_centroids(centroids, min_distance):\n",
    "        filtered_centroids = []\n",
    "        \n",
    "        for centroid in centroids:\n",
    "            if all(np.linalg.norm(centroid - other) >= min_distance for other in filtered_centroids):\n",
    "                filtered_centroids.append(centroid)\n",
    "        \n",
    "        return np.array(filtered_centroids)\n",
    "\n",
    "    filtered_centroids = filter_centroids(centers, _min_dist)\n",
    "\n",
    "    return filtered_centroids\n",
    "\n",
    "\n",
    "\n",
    "def seismic_centers_detect(tr_times, tr_data, tr_sampling_rate, _target=None, \n",
    "                        _STA=120, _LTA=600, _high_freq_thresh=0.05, _power_thresh=0.4, plot=False):\n",
    "    \n",
    "\n",
    "    act_quake_cat = _target\n",
    "    local_acc = 0\n",
    "\n",
    "    fp, t, sxx = signal.spectrogram(tr_data, tr_sampling_rate, nperseg=256, noverlap=128, scaling='density')\n",
    "    vmax = sxx.max()\n",
    "    vmin = sxx.min()\n",
    "\n",
    "    # Sampling frequency of our trace\n",
    "    df = tr_sampling_rate\n",
    "\n",
    "    sta_len = _STA\n",
    "    lta_len = _LTA\n",
    "\n",
    "    # Run Obspy's STA/LTA to obtain a characteristic function\n",
    "    # This function basically calculates the ratio of amplitude between the short-term \n",
    "    # and long-term windows, moving consecutively in time across the data\n",
    "    cft = classic_sta_lta(tr_data, int(sta_len * df), int(lta_len * df))\n",
    "\n",
    "    if plot:\n",
    "        # Plot characteristic function\n",
    "        fig, (ax, ax1 ,ax2) = plt.subplots(3, 1, figsize=(12, 8))\n",
    "\n",
    "        ax.plot(tr_times,tr_data)\n",
    "        ax.set_xlim([min(tr_times),max(tr_times)])\n",
    "        ax.set_ylabel('Velocity (m/s)')\n",
    "        #ax.set_xlabel('Time (s)')\n",
    "        ax.set_title('Filtered')\n",
    "        #ax.set_title(f'{test_filename}', fontweight='bold') \n",
    "\n",
    "\n",
    "        # Plot characteristic function\n",
    "        ax1.plot(tr_times, cft)\n",
    "        #ax1.set_title('Unfiltered' if f == 0 else f'Filtered - bandpass [{minfreq} {maxfreq}]')\n",
    "        ax1.set_xlim([min(tr_times), max(tr_times)])\n",
    "        #ax1.set_xlabel('Time (s)')\n",
    "        ax1.set_ylabel('Characteristic function')\n",
    "        \n",
    "        #ax1.legend()\n",
    "\n",
    "        ## Plot spectrogram\n",
    "        vals = ax2.pcolormesh(t, fp, sxx, cmap=cm.jet, vmin = vmin, vmax=vmax)\n",
    "        #vals = ax2.pcolormesh(t, fp, sxx, cmap=cm.jet, vmin = 0, vmax=1)\n",
    "\n",
    "        ax2.set_xlim([min(tr_times), max(tr_times)])\n",
    "        ax2.set_xlabel(f'Time (s)', fontweight='bold')\n",
    "        ax2.set_ylabel('Frequency (Hz)')\n",
    "        \n",
    "\n",
    "        #cbar = plt.colorbar(vals, ax=ax2, orientation='horizontal')\n",
    "        #cbar.set_label('Power ((m/s)^2/sqrt(Hz))', fontweight='bold')\n",
    "\n",
    "    if plot and _target:\n",
    "        ax.axvline(x=act_quake_cat, c='red')\n",
    "        ax1.axvline(x=act_quake_cat, c='red')\n",
    "        ax2.axvline(x=act_quake_cat, c='red', linewidth=1)\n",
    "\n",
    "\n",
    "    # Normalize fp and sxx\n",
    "    fp = (fp - np.min(fp)) / (np.max(fp) - np.min(fp))\n",
    "    sxx = (sxx - np.min(sxx)) / (np.max(sxx) - np.min(sxx))  \n",
    "\n",
    "    high_freq_mask = fp >= _high_freq_thresh  # Mask for high frequencies\n",
    "    high_power_mask = sxx > _power_thresh    # Mask for sections with high power\n",
    "    # Combined mask for high-frequency and high-power regions\n",
    "    combined_mask = np.logical_and(high_freq_mask[:, None], high_power_mask)\n",
    "    # Extract high-frequency sections\n",
    "    high_freq_sections = []\n",
    "    for i in range(sxx.shape[1]):  # Iterate over time steps\n",
    "        high_freqs_at_t = fp[combined_mask[:, i]]  # Extract frequencies for time step i\n",
    "        if len(high_freqs_at_t) > 0:\n",
    "            high_freq_sections.append((t[i], high_freqs_at_t))\n",
    "\n",
    "    if len(high_freq_sections) > 0:\n",
    "        hf_points = [row[0] for row in high_freq_sections]\n",
    "        try:\n",
    "            centers = find_clusters(hf_points)\n",
    "            swd_centers = list(itertools.chain.from_iterable(centers))\n",
    "\n",
    "            for v in swd_centers:\n",
    "                if plot:\n",
    "                    ax2.axvline(x=v, c='yellow', linewidth=1)\n",
    "                    ax.axvline(x=v-2500, c='blue', linewidth=4)\n",
    "                    ax.axvline(x=min((v+6500),(tr_times[-1]-100)), c='blue', linewidth=4)\n",
    "                if _target and v-2500 <= act_quake_cat <= v+6500:\n",
    "                    local_acc = 1\n",
    "        except:\n",
    "            print('Number of samples less than number of clusters')\n",
    "            swd_centers = None\n",
    "\n",
    "    return swd_centers, local_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e60411",
   "metadata": {},
   "source": [
    "### Accuracy Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cd0be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  file_name  \\\n",
      "0    xa.s12.00.mhz.1970-01-19HR00_evid00002   \n",
      "1    xa.s12.00.mhz.1970-03-25HR00_evid00003   \n",
      "2    xa.s12.00.mhz.1970-03-26HR00_evid00004   \n",
      "3    xa.s12.00.mhz.1970-04-25HR00_evid00006   \n",
      "4    xa.s12.00.mhz.1970-04-26HR00_evid00007   \n",
      "..                                      ...   \n",
      "72   xa.s12.00.mhz.1975-05-04HR00_evid00192   \n",
      "73   xa.s12.00.mhz.1975-06-24HR00_evid00196   \n",
      "74   xa.s12.00.mhz.1975-06-26HR00_evid00198   \n",
      "75  XB.ELYSE.02.BHV.2022-01-02HR04_evid0006   \n",
      "76  XB.ELYSE.02.BHV.2022-02-03HR08_evid0005   \n",
      "\n",
      "                                            rel_times  \\\n",
      "0   [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "1   [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "2   [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "3   [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "4   [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "..                                                ...   \n",
      "72  [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "73  [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "74  [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "75  [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0...   \n",
      "76  [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0...   \n",
      "\n",
      "                                                 data  \\\n",
      "0   [-6.230017720510135e-16, -3.472013438962138e-1...   \n",
      "1   [-5.550144479984088e-17, -3.0949191046807696e-...   \n",
      "2   [-2.8564306558024815e-16, -1.5911221298656733e...   \n",
      "3   [9.128868235422447e-17, 5.089678594808115e-16,...   \n",
      "4   [-1.6033143390064217e-18, -8.82502002245986e-1...   \n",
      "..                                                ...   \n",
      "72  [8.483378135502545e-19, 4.449762068087465e-18,...   \n",
      "73  [1.1946263866745526e-16, 6.669826693659719e-16...   \n",
      "74  [-1.9567964119833714e-17, -1.0903748481579898e...   \n",
      "75  [0.0, 1.7053890037984885e-07, 2.38751059419158...   \n",
      "76  [0.0, 4.34874672769765e-08, 5.330486968118154e...   \n",
      "\n",
      "                     start_time                     end_time   target  \\\n",
      "0   1970-01-19T00:00:00.665000Z  1970-01-20T00:00:02.778208Z  73500.0   \n",
      "1   1970-03-25T00:00:00.440000Z  1970-03-26T00:00:01.949434Z  12720.0   \n",
      "2   1970-03-26T00:00:00.565000Z  1970-03-27T00:00:02.074434Z  73020.0   \n",
      "3   1970-04-25T00:00:00.196000Z  1970-04-26T00:00:02.309208Z   4440.0   \n",
      "4   1970-04-26T00:00:00.660000Z  1970-04-27T00:00:02.169434Z  52140.0   \n",
      "..                          ...                          ...      ...   \n",
      "72  1975-05-04T00:00:00.457000Z  1975-05-05T00:00:03.023038Z  36300.0   \n",
      "73  1975-06-24T00:00:00.239000Z  1975-06-25T00:00:01.748434Z  57780.0   \n",
      "74  1975-06-26T00:00:00.542000Z  1975-06-27T00:00:01.447660Z  12240.0   \n",
      "75  2022-01-02T04:00:00.025000Z  2022-01-02T04:59:59.975000Z   2130.0   \n",
      "76  2022-02-03T08:00:00.009000Z  2022-02-03T08:59:59.959000Z    507.0   \n",
      "\n",
      "    sampling_rate  \n",
      "0           6.625  \n",
      "1           6.625  \n",
      "2           6.625  \n",
      "3           6.625  \n",
      "4           6.625  \n",
      "..            ...  \n",
      "72          6.625  \n",
      "73          6.625  \n",
      "74          6.625  \n",
      "75         20.000  \n",
      "76         20.000  \n",
      "\n",
      "[77 rows x 7 columns]\n",
      "                                   file_name  \\\n",
      "0     xa.s12.00.mhz.1969-12-16HR00_evid00006   \n",
      "1     xa.s12.00.mhz.1970-01-09HR00_evid00007   \n",
      "2     xa.s12.00.mhz.1970-02-07HR00_evid00014   \n",
      "3     xa.s12.00.mhz.1970-02-18HR00_evid00016   \n",
      "4     xa.s12.00.mhz.1970-03-14HR00_evid00018   \n",
      "..                                       ...   \n",
      "100  XB.ELYSE.02.BHV.2021-05-02HR01_evid0017   \n",
      "101  XB.ELYSE.02.BHV.2021-10-11HR23_evid0011   \n",
      "102  XB.ELYSE.02.BHV.2021-12-24HR22_evid0007   \n",
      "103  XB.ELYSE.02.BHV.2022-04-09HR22_evid0002   \n",
      "104  XB.ELYSE.02.BHV.2022-05-04HR23_evid0001   \n",
      "\n",
      "                                             rel_times  \\\n",
      "0    [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "1    [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "2    [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "3    [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "4    [0.0, 0.1509433962264151, 0.3018867924528302, ...   \n",
      "..                                                 ...   \n",
      "100  [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0...   \n",
      "101  [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0...   \n",
      "102  [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0...   \n",
      "103  [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0...   \n",
      "104  [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0...   \n",
      "\n",
      "                                                  data  \\\n",
      "0    [0.0, -5.646490685554848e-17, -3.5694091553713...   \n",
      "1    [-1.091209314805774e-16, -6.08690054447344e-16...   \n",
      "2    [9.07629921335777e-17, 4.95280955553044e-16, 1...   \n",
      "3    [9.975929699587747e-16, 5.559441790730426e-15,...   \n",
      "4    [-9.564799539978048e-18, -5.363334652588157e-1...   \n",
      "..                                                 ...   \n",
      "100  [0.0, 4.903025903512072e-08, 8.519758575808287...   \n",
      "101  [0.0, 2.9472230353627474e-07, 4.05541454680156...   \n",
      "102  [0.0, 9.77829135703316e-07, 8.459528425342803e...   \n",
      "103  [0.0, 9.641144076460256e-08, 1.005561954845729...   \n",
      "104  [0.0, 1.3825226353352035e-06, 1.18399773491109...   \n",
      "\n",
      "                      start_time                     end_time  sampling_rate  \n",
      "0    1969-12-16T00:00:00.178000Z  1969-12-17T00:00:03.498755Z          6.625  \n",
      "1    1970-01-09T00:00:00.126000Z  1970-01-10T00:00:03.446755Z          6.625  \n",
      "2    1970-02-07T00:00:00.571000Z  1970-02-08T00:00:03.891755Z          6.625  \n",
      "3    1970-02-18T00:00:00.149000Z  1970-02-19T00:00:02.262208Z          6.625  \n",
      "4    1970-03-14T00:00:00.520000Z  1970-03-15T00:00:03.840755Z          6.625  \n",
      "..                           ...                          ...            ...  \n",
      "100  2021-05-02T01:00:00.025000Z  2021-05-02T01:59:59.975000Z         20.000  \n",
      "101  2021-10-11T23:00:00.039000Z  2021-10-11T23:59:59.989000Z         20.000  \n",
      "102  2021-12-24T22:00:00.041000Z  2021-12-24T22:59:59.991000Z         20.000  \n",
      "103  2022-04-09T22:00:00.035000Z  2022-04-09T22:59:59.985000Z         20.000  \n",
      "104  2022-05-04T23:00:00.048000Z  2022-05-04T23:59:59.948000Z         20.000  \n",
      "\n",
      "[105 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(['./data/lunar/training/data/S12_GradeA/', './data/mars/training/data/'], \n",
    "                      ['./data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv', './data/mars/training/catalogs/Mars_InSight_training_catalog_final.csv'])\n",
    "\n",
    "test_data = get_test_data(['./data/lunar/test/data/S12_GradeB/', './data/lunar/test/data/S15_GradeA/', './data/lunar/test/data/S15_GradeB/', \n",
    "                           './data/lunar/test/data/S16_GradeA/', './data/lunar/test/data/S16_GradeB/', './data/mars/test/data/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "683daa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:\n",
      "Number of samples less than number of clusters\n",
      "Number of samples less than number of clusters\n",
      "Number of samples less than number of clusters\n",
      "Number of samples less than number of clusters\n",
      "Number of samples less than number of clusters\n",
      "Number of samples less than number of clusters\n",
      "0.8701298701298701\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(df):\n",
    "    num_rows = len(df)\n",
    "    accuracy = 0\n",
    "    for row in df.itertuples():\n",
    "        swd_centers, tmp_acc = seismic_centers_detect(row.rel_times, row.data, row.sampling_rate, _target=row.target, \n",
    "                        _STA=120, _LTA=600, _high_freq_thresh=0.05, _power_thresh=0.4)\n",
    "        accuracy += tmp_acc\n",
    "    return accuracy / num_rows\n",
    "\n",
    "print(\"ACCURACY:\")\n",
    "print(compute_accuracy(train_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
